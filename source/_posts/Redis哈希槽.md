---
title: Redis哈希槽
date: 2020-10-24 15:39:27
tags: 
- 一致性哈希
- 哈希槽
- redis
categories: 缓存相关
---

如果Redis只用复制功能做主从，那么当数据量巨大的情况下，单机情况下可能已经承受不下一份数据，更不用说是主从都要各自保存一份完整的数据。在这种情况下，数据分片是一个非常好的解决办法。

Redis的Cluster正是用于解决该问题。它主要提供两个功能：

1. 自动对数据分片，落到各个节点上；
2. 即使集群部分节点失效或者连接不上，依然可以继续处理命令。

## 简单哈希算法

假设有三台机，数据落在哪台机的算法为

```
c = Hash(key) % 3
```

例如，key=A的哈希值为4，4%3=1，则落在第二台机。Key=B哈希值为11，11%3=2，则落在第三台机上。

利用这样的算法，假设现在数据量太大了，需要增加一台机器。A原本落在第二台上，现在根据算法4%4=0，落到了第一台机器上了，但是第一台机器上根本没有A的值。这样的算法会导致增加机器或减少机器的时候，引起大量的缓存击穿，造成缓存雪崩。

## 一致性哈希算法

在1997年，麻省理工学院的Karger等人提出了**一致性哈希算法**，为的就是解决分布式缓存的问题。

在**一致性哈希算法**中，整个哈希空间是一个**虚拟圆环**

<p><img src="/assets/blogImg/Redis哈希槽_01.png" width="350"></p>

假设有四个节点Node A、B、C、D，经过ip地址的哈希计算，它们的位置如下

<p><img src="/assets/blogImg/Redis哈希槽_02.png" width="350"></p>

有4个存储对象Object A、B、C、D，经过对Key的哈希计算后，它们的位置如下
<p><img src="/assets/blogImg/Redis哈希槽_03.png" width="350"></p>

对于各个Object，它所真正的存储位置是按顺时针找到的第一个存储节点。例如Object A顺时针找到的第一个节点是Node A，所以Node A负责存储Object A，Object B存储在Node B。

**一致性哈希算法大概如此，那么它的容错性和扩展性如何呢？**

假设Node C节点挂掉了，Object C的存储丢失，那么它顺时针找到的最新节点是Node D。也就是说Node C挂掉了，受影响仅仅包括Node B到Node C区间的数据，并且这些数据会转移到Node D进行存储。

<p><img src="/assets/blogImg/Redis哈希槽_04.png" width="350"></p>

同理，假设现在数据量大了，需要增加一台节点Node X。Node X的位置在Node B到Node C直接，那么受到影响的仅仅是Node B到Node X间的数据，它们要重新落到Node X上。

所以一致性哈希算法对于容错性和扩展性有非常好的支持。但一致性哈希算法也有一个严重的问题，就是**数据倾斜**。

如果在分片的集群中，节点太少，并且分布不均，一致性哈希算法就会出现部分节点数据太多，部分节点数据太少。也就是说无法控制节点存储数据的分配。如下图，大部分数据都在A上了，B的数据比较少。

<p><img src="/assets/blogImg/Redis哈希槽_05.png" width="350"></p>

## Redis哈希槽

Redis集群（Cluster）并没有选用上面一致性哈希，而是采用了**哈希槽**（Hash Slot）的这种概念。主要的原因就是上面所说的，一致性哈希算法对于数据分布、节点位置的控制并不是很友好。

首先**哈希槽**其实包含两个概念，第一个是**哈希算法**。Redis Cluster的hash算法不是简单的hash()，而是crc16算法，一种校验算法。另外一个就是**槽位**的概念，空间分配的规则。其实哈希槽的本质和一致性哈希算法非常相似，不同点就是对于哈希空间的定义。一致性哈希的空间是一个圆环，节点分布是基于圆环的，无法很好的控制数据分布。而Redis Cluster的槽位空间是自定义分配的，类似于Windows盘分区的概念。这种分区是可以自定义大小，自定义位置的。

Redis Cluster包含了16384个哈希槽，每个Key通过计算后都会落在具体一个槽位上，而这个槽位是属于哪个存储节点的，则由用户自己定义分配。例如机器硬盘小的，可以分配少一点槽位，硬盘大的可以分配多一点。如果节点硬盘都差不多则可以平均分配。所以哈希槽这种概念很好地解决了一致性哈希的弊端。

另外在**容错性**和**扩展性**上，与一致性哈希一样，都是对受影响的数据进行转移。而哈希槽本质上是对槽位的转移，把故障节点负责的槽位转移到其他正常的节点上。扩展节点也是一样，把其他节点上的槽位转移到新的节点上。

**但一定要注意的是，对于槽位的转移和分派，Redis集群是不会自动进行的，而是需要人工配置的。所以Redis集群的高可用是依赖于节点的主从复制与主从间的自动故障转移。**

## 引用

https://www.cnblogs.com/zackku/p/10094940.html